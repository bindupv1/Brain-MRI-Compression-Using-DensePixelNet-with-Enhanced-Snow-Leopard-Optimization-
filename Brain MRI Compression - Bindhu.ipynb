{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6c1d0c2-aba6-4fde-a2fa-e88a78539524",
   "metadata": {},
   "source": [
    "# 1. ROI-based Image Compression Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7470837f-67f2-4178-9464-063c609de828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths\n",
    "input_path = \"D:/F4our Research/Bindhu/Dataset\"\n",
    "output_path = \"Bindhu/Brain_MRI_Compression/Framework\"\n",
    "\n",
    "# Ensure output path exists\n",
    "Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load YOLO model\n",
    "def load_yolo_model():\n",
    "    yolo_cfg = 'yolov4.cfg'     \n",
    "    yolo_weights = 'yolov4.weights'\n",
    "    net = cv2.dnn.readNetFromDarknet(yolo_cfg, yolo_weights)\n",
    "    return net\n",
    "\n",
    "# Detect ROIs using YOLO (OpenCV DNN)\n",
    "def detect_roi(image, net):\n",
    "    # Prepare the image for YOLO\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Get the layer names and output layers\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layer_indices = net.getUnconnectedOutLayers()\n",
    "    output_layers = [layer_names[i - 1] for i in output_layer_indices]\n",
    "\n",
    "    # Perform forward pass and get detections\n",
    "    detections = net.forward(output_layers)\n",
    "\n",
    "    height, width = image.shape[:2]\n",
    "    boxes = []\n",
    "\n",
    "    # Process the detections\n",
    "    for detection in detections:\n",
    "        for obj in detection:\n",
    "            scores = obj[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:  # Confidence threshold\n",
    "                center_x = int(obj[0] * width)\n",
    "                center_y = int(obj[1] * height)\n",
    "                w = int(obj[2] * width)\n",
    "                h = int(obj[3] * height)\n",
    "                x1 = max(0, int(center_x - w / 2))\n",
    "                y1 = max(0, int(center_y - h / 2))\n",
    "                x2 = min(width, x1 + w)\n",
    "                y2 = min(height, y1 + h)\n",
    "                boxes.append([x1, y1, x2, y2])  # Add bounding box coordinates\n",
    "    return boxes\n",
    "\n",
    "# Compress image by reducing ROI size\n",
    "def compress_image(image, roi_boxes):\n",
    "    for box in roi_boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "\n",
    "        # Validate ROI boundaries\n",
    "        if x1 >= x2 or y1 >= y2:\n",
    "            continue  # Skip invalid boxes\n",
    "\n",
    "        roi = image[y1:y2, x1:x2]\n",
    "        if roi.size == 0:\n",
    "            continue  # Skip empty ROIs\n",
    "\n",
    "        # Compress ROI to 64x64 and resize it back to its original dimensions\n",
    "        compressed_roi = cv2.resize(roi, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "        resized_roi = cv2.resize(compressed_roi, (x2 - x1, y2 - y1), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Replace the original ROI with the resized version\n",
    "        image[y1:y2, x1:x2] = resized_roi\n",
    "    return image\n",
    "\n",
    "# Process images in the input folder and apply ROI compression\n",
    "def process_images(input_folder, output_folder, net):\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):  # Supported image formats\n",
    "                image_path = os.path.join(root, file)\n",
    "                print(f\"Processing: {image_path}\")\n",
    "\n",
    "                # Read and resize the image to 255x255\n",
    "                img = cv2.imread(image_path)\n",
    "                if img is None:\n",
    "                    print(f\"Error reading {image_path}. Skipping...\")\n",
    "                    continue\n",
    "                \n",
    "                img = cv2.resize(img, (255, 255), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                # Detect ROIs using YOLO\n",
    "                boxes = detect_roi(img, net)\n",
    "\n",
    "                # Compress detected ROIs\n",
    "                compressed_img = compress_image(img, boxes)\n",
    "\n",
    "                # Reconstruct output subfolder path\n",
    "                relative_path = os.path.relpath(root, input_folder)\n",
    "                output_subfolder = os.path.join(output_folder, relative_path)\n",
    "                Path(output_subfolder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                # Save the compressed image\n",
    "                output_file_path = os.path.join(output_subfolder, file)\n",
    "                cv2.imwrite(output_file_path, compressed_img)\n",
    "                print(f\"Compressed image saved to: {output_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the YOLO model\n",
    "    net = load_yolo_model()\n",
    "\n",
    "    # Process all images in the input folder\n",
    "    process_images(input_path, output_path, net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b6de66-1c57-4650-802f-680607944865",
   "metadata": {},
   "source": [
    "# 2. ROI-based Compression using DensePixelNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138a0d7-9735-4498-aaea-271feb0cbb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "def create_output_structure(input_path, output_path):\n",
    "    for root, dirs, _ in os.walk(input_path):\n",
    "        for dir_name in dirs:\n",
    "            src_dir = os.path.join(root, dir_name)\n",
    "            rel_path = os.path.relpath(src_dir, input_path)\n",
    "            dest_dir = os.path.join(output_path, rel_path)\n",
    "            if not os.path.exists(dest_dir):\n",
    "                os.makedirs(dest_dir)\n",
    "\n",
    "def detect_and_save_roi(input_path, output_path, yolo_model, yolo_classes):\n",
    "    for root, _, files in tqdm(os.walk(input_path), desc=\"Processing images\"):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                input_img_path = os.path.join(root, file)\n",
    "                rel_path = os.path.relpath(root, input_path)\n",
    "                output_img_dir = os.path.join(output_path, rel_path)\n",
    "\n",
    "                # Load the input image\n",
    "                img = cv2.imread(input_img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "\n",
    "                # YOLOv7 detection\n",
    "                roi_image, bbox = detect_roi_with_yolo(img, yolo_model, yolo_classes)\n",
    "\n",
    "                # Save the ROI-detected image\n",
    "                if not os.path.exists(output_img_dir):\n",
    "                    os.makedirs(output_img_dir)\n",
    "                roi_output_path = os.path.join(output_img_dir, file)\n",
    "                cv2.imwrite(roi_output_path, roi_image)\n",
    "\n",
    "                # Combine side-by-side original and ROI for display\n",
    "                combined_img = combine_images_side_by_side(img, roi_image)\n",
    "                display_image_in_notebook(combined_img, \"Input Image and ROI Detected Image\")\n",
    "                print(f\"Processed and saved ROI: {roi_output_path}\")\n",
    "\n",
    "def detect_roi_with_yolo(image, model, classes):\n",
    "    # For detected a ROI\n",
    "    height, width, _ = image.shape\n",
    "    bbox = (int(width * 0.3), int(height * 0.3), int(width * 0.7), int(height * 0.7))  # Simulated bounding box\n",
    "\n",
    "    # Crop the ROI from the image\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    roi_image = image[y1:y2, x1:x2]\n",
    "    \n",
    "    return roi_image, bbox\n",
    "\n",
    "# Build the DensePixelNet\n",
    "class BottleneckLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, growth_rate):\n",
    "        super(BottleneckLayer, self).__init__()\n",
    "        self.growth_rate = growth_rate\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.conv1 = layers.Conv2D(4 * growth_rate, kernel_size=1, strides=1, padding='valid', use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.conv2 = layers.Conv2D(growth_rate, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.conv1(tf.nn.relu(self.bn1(x)))\n",
    "        out = self.conv2(tf.nn.relu(self.bn2(out)))\n",
    "        return tf.concat([x, out], axis=-1)\n",
    "\n",
    "\n",
    "class TransitionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, out_channels):\n",
    "        super(TransitionLayer, self).__init__()\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.conv = layers.Conv2D(out_channels, kernel_size=1, strides=1, padding='valid', use_bias=False)\n",
    "        self.avg_pool = layers.AveragePooling2D(pool_size=2, strides=2)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.conv(tf.nn.relu(self.bn(x)))\n",
    "        return self.avg_pool(out)\n",
    "\n",
    "\n",
    "class DenseBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, growth_rate):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.layers_list = []\n",
    "        for _ in range(num_layers):\n",
    "            self.layers_list.append(BottleneckLayer(growth_rate))\n",
    "\n",
    "    def call(self, x):\n",
    "        for layer in self.layers_list:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DensePixelNet(Model):\n",
    "    def __init__(self, input_channels=1, num_classes=1, growth_rate=12, block_config=(4, 4, 4), compression=0.5):\n",
    "        super(DensePixelNet, self).__init__()\n",
    "        num_channels = 2 * growth_rate  # Initial number of channels\n",
    "        self.conv1 = layers.Conv2D(num_channels, kernel_size=7, strides=2, padding='same', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.max_pool = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')\n",
    "\n",
    "        self.dense_blocks = []\n",
    "        self.trans_layers = []\n",
    "\n",
    "        # Add Dense Blocks and Transition Layers\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            self.dense_blocks.append(DenseBlock(num_layers, growth_rate))\n",
    "            num_channels += num_layers * growth_rate\n",
    "            if i != len(block_config) - 1:  # No transition layer after the last block\n",
    "                out_channels = int(num_channels * compression)\n",
    "                self.trans_layers.append(TransitionLayer(out_channels))\n",
    "                num_channels = out_channels\n",
    "\n",
    "        # Final classification layer (pixel-level output)\n",
    "        self.bn_final = layers.BatchNormalization()\n",
    "        self.conv_final = layers.Conv2D(num_classes, kernel_size=1, strides=1, padding='valid')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.max_pool(tf.nn.relu(self.bn1(self.conv1(x))))\n",
    "        for i, dense_block in enumerate(self.dense_blocks):\n",
    "            x = dense_block(x)\n",
    "            if i < len(self.trans_layers):\n",
    "                x = self.trans_layers[i](x)\n",
    "        x = tf.nn.relu(self.bn_final(x))\n",
    "        return self.conv_final(x)\n",
    "\n",
    "def combine_images_side_by_side(original_img, roi_img):\n",
    "    roi_resized = cv2.resize(roi_img, (original_img.shape[1] // 2, original_img.shape[0]))\n",
    "    combined = cv2.hconcat([original_img, roi_resized])\n",
    "    return combined\n",
    "\n",
    "def display_image_in_notebook(image, title=\"Image\"):\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # Define paths\n",
    "    input_path = 'Bindhu/Brain_MRI_Compression/Framework'\n",
    "    output_path = 'Bindhu/Brain_MRI_Compression/RoI_Images'\n",
    "\n",
    "    # Placeholder for YOLOv7 model loading\n",
    "    yolo_model = None  # Load your YOLOv7 model here\n",
    "    yolo_classes = ['brain_roi']\n",
    "\n",
    "    # Step 1: Recreate the directory structure in the output folder\n",
    "    create_output_structure(input_path, output_path)\n",
    "\n",
    "    # Step 2: Detect ROI and save images\n",
    "    detect_and_save_roi(input_path, output_path, yolo_model, yolo_classes)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6444021-cb77-45d6-a618-89931ba5d040",
   "metadata": {},
   "source": [
    "# 3.Feature Extraction using DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3bdbe6-3162-4d83-8751-1828b2d0b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Path to the root folder containing the segmented images\n",
    "input_path = 'Bindhu/Brain_MRI_Compression/RoI_Images'\n",
    "# Output path for the CSV file\n",
    "output_csv = 'Bindhu_Brain_MRI_Features.csv'\n",
    "\n",
    "# Function to extract features from an image\n",
    "def extract_features(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Resize the image (change size as needed)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "\n",
    "    # Normalize the image\n",
    "    image = image / 255.0\n",
    "\n",
    "    # Extract features\n",
    "    mean_color = np.mean(image, axis=(0, 1))  # Mean color per channel\n",
    "    std_color = np.std(image, axis=(0, 1))    # Standard deviation per channel\n",
    "    min_color = np.min(image, axis=(0, 1))    # Minimum color per channel\n",
    "    max_color = np.max(image, axis=(0, 1))    # Maximum color per channel\n",
    "    median_color = np.median(image, axis=(0, 1))  # Median color per channel\n",
    "    var_color = np.var(image, axis=(0, 1))     # Variance per channel\n",
    "\n",
    "    # Flatten the features and return as a list\n",
    "    features = np.concatenate((mean_color, std_color, min_color, max_color, median_color, var_color)).tolist()\n",
    "    \n",
    "    return features\n",
    "# Define the DNN Architecture\n",
    "def build_dnn_autoencoder(input_shape=(128, 128, 1)):\n",
    "    # Input Layer\n",
    "    inputs = layers.Input(shape=input_shape, name='Input_Layer')\n",
    "    # Convolutional Layer 1\n",
    "    x = layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', name='Conv1')(inputs)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2), padding='same', name='Pool1')(x)\n",
    "    \n",
    "    # Convolutional Layer 2\n",
    "    x = layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same', name='Conv2')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2), padding='same', name='Pool2')(x)\n",
    "\n",
    "    # ----- Compression Block -----\n",
    "    # Dense bottleneck layer\n",
    "    x = layers.Flatten(name='Flatten')(x)\n",
    "    x = layers.Dense(units=256, activation='relu', name='Bottleneck')(x)\n",
    "\n",
    "    # ----- Reconstruction Block -----\n",
    "    # Upsampling to recover dimensions\n",
    "    x = layers.Dense(units=(32 * 32 * 64), activation='relu', name='Dense_Expand')(x)\n",
    "    x = layers.Reshape(target_shape=(32, 32, 64), name='Reshape')(x)\n",
    "    \n",
    "    # Transposed Convolutional Layers\n",
    "    x = layers.UpSampling2D(size=(2, 2), name='Upsample1')(x)\n",
    "    x = layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), activation='relu', padding='same', name='Deconv1')(x)\n",
    "    \n",
    "    x = layers.UpSampling2D(size=(2, 2), name='Upsample2')(x)\n",
    "    x = layers.Conv2DTranspose(filters=32, kernel_size=(3, 3), activation='relu', padding='same', name='Deconv2')(x)\n",
    "\n",
    "    # Output Layer\n",
    "    outputs = layers.Conv2D(filters=1, kernel_size=(3, 3), activation='sigmoid', padding='same', name='Output_Layer')(x)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs, outputs, name=\"DNN_Image_Compression\")\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "# Initialize a list to store the features\n",
    "features_list = []\n",
    "\n",
    "# Walk through the input directory and process each image\n",
    "for root, _, files in os.walk(input_path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):  # Add more formats if needed\n",
    "            image_path = os.path.join(root, file)\n",
    "            features = extract_features(image_path)\n",
    "            features_list.append(features)\n",
    "\n",
    "# Create a DataFrame with the features\n",
    "feature_columns = [f'DNN_{i + 1}' for i in range(len(features_list[0]))]\n",
    "features_df = pd.DataFrame(features_list, columns=feature_columns)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "features_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Features extracted and saved to {output_csv}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30ac6da8-cb65-4298-9b51-49497ca63c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNN_1</th>\n",
       "      <th>DNN_2</th>\n",
       "      <th>DNN_3</th>\n",
       "      <th>DNN_4</th>\n",
       "      <th>DNN_5</th>\n",
       "      <th>DNN_6</th>\n",
       "      <th>DNN_7</th>\n",
       "      <th>DNN_8</th>\n",
       "      <th>DNN_9</th>\n",
       "      <th>DNN_10</th>\n",
       "      <th>DNN_11</th>\n",
       "      <th>DNN_12</th>\n",
       "      <th>DNN_13</th>\n",
       "      <th>DNN_14</th>\n",
       "      <th>DNN_15</th>\n",
       "      <th>DNN_16</th>\n",
       "      <th>DNN_17</th>\n",
       "      <th>DNN_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.264492</td>\n",
       "      <td>0.264492</td>\n",
       "      <td>0.264492</td>\n",
       "      <td>0.110687</td>\n",
       "      <td>0.110687</td>\n",
       "      <td>0.110687</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.937255</td>\n",
       "      <td>0.937255</td>\n",
       "      <td>0.937255</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.012252</td>\n",
       "      <td>0.012252</td>\n",
       "      <td>0.012252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.187167</td>\n",
       "      <td>0.187167</td>\n",
       "      <td>0.187167</td>\n",
       "      <td>0.078741</td>\n",
       "      <td>0.078741</td>\n",
       "      <td>0.078741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.006200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.181551</td>\n",
       "      <td>0.181551</td>\n",
       "      <td>0.181551</td>\n",
       "      <td>0.020986</td>\n",
       "      <td>0.020986</td>\n",
       "      <td>0.020986</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.272863</td>\n",
       "      <td>0.272863</td>\n",
       "      <td>0.272863</td>\n",
       "      <td>0.125662</td>\n",
       "      <td>0.125662</td>\n",
       "      <td>0.125662</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.015791</td>\n",
       "      <td>0.015791</td>\n",
       "      <td>0.015791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.219161</td>\n",
       "      <td>0.219161</td>\n",
       "      <td>0.219161</td>\n",
       "      <td>0.074494</td>\n",
       "      <td>0.074494</td>\n",
       "      <td>0.074494</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>0.005549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DNN_1     DNN_2     DNN_3     DNN_4     DNN_5     DNN_6     DNN_7  \\\n",
       "0  0.264492  0.264492  0.264492  0.110687  0.110687  0.110687  0.015686   \n",
       "1  0.187167  0.187167  0.187167  0.078741  0.078741  0.078741  0.000000   \n",
       "2  0.181551  0.181551  0.181551  0.020986  0.020986  0.020986  0.035294   \n",
       "3  0.272863  0.272863  0.272863  0.125662  0.125662  0.125662  0.015686   \n",
       "4  0.219161  0.219161  0.219161  0.074494  0.074494  0.074494  0.007843   \n",
       "\n",
       "      DNN_8     DNN_9    DNN_10    DNN_11    DNN_12    DNN_13    DNN_14  \\\n",
       "0  0.015686  0.015686  0.937255  0.937255  0.937255  0.270588  0.270588   \n",
       "1  0.000000  0.000000  0.627451  0.627451  0.627451  0.200000  0.200000   \n",
       "2  0.035294  0.035294  0.372549  0.372549  0.372549  0.180392  0.180392   \n",
       "3  0.015686  0.015686  0.815686  0.815686  0.815686  0.266667  0.266667   \n",
       "4  0.007843  0.007843  0.698039  0.698039  0.698039  0.231373  0.231373   \n",
       "\n",
       "     DNN_15    DNN_16    DNN_17    DNN_18  \n",
       "0  0.270588  0.012252  0.012252  0.012252  \n",
       "1  0.200000  0.006200  0.006200  0.006200  \n",
       "2  0.180392  0.000440  0.000440  0.000440  \n",
       "3  0.266667  0.015791  0.015791  0.015791  \n",
       "4  0.231373  0.005549  0.005549  0.005549  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "features = pd.read_csv('Bindhu_Brain_MRI_Features.csv')\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1af068-1005-4eff-bb1b-4bdbba77b2bc",
   "metadata": {},
   "source": [
    "# 4.Original Data converted into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f0c6ce-c44d-4923-8937-864d48b5722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the input and output paths\n",
    "input_path = r\"D:/F4our Research/Bindhu/Dataset\"\n",
    "output_csv = \"Bindhu_Brain_MRI_original.csv\"\n",
    "\n",
    "# List to store the image names and their labels\n",
    "data = []\n",
    "\n",
    "# Allowed image extensions\n",
    "image_extensions = {'.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff', '.gif'}\n",
    "\n",
    "# Define label mapping\n",
    "label_mapping = {\n",
    "    'notumor': 0,\n",
    "    'glioma': 1,\n",
    "    'meningioma': 2,\n",
    "    'pituitary': 3\n",
    "}\n",
    "\n",
    "# Walk through the directory\n",
    "for root, dirs, files in os.walk(input_path):\n",
    "    # Get the folder name (label) and apply mapping\n",
    "    folder_name = os.path.basename(root).lower()\n",
    "    label = label_mapping.get(folder_name, -1)  # Default to -1 if not in mapping\n",
    "\n",
    "    # Iterate over files in the folder\n",
    "    for file in files:\n",
    "        # Check if the file is an image\n",
    "        if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "            # Full path to the image file\n",
    "            image_name = os.path.join(root, file)\n",
    "\n",
    "            # Append image name and mapped label to the data list\n",
    "            data.append([image_name, label])\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame(data, columns=['Image_name', 'Label'])\n",
    "\n",
    "# Filter out any rows with invalid labels (-1)\n",
    "df = df[df['Label'] != -1]\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Dataframe successfully saved to {output_csv}, containing {len(df)} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4279af8a-b53e-467e-8938-54df7311358e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_name</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Image_name  Label\n",
       "0  D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...      1\n",
       "1  D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...      1\n",
       "2  D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...      1\n",
       "3  D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...      1\n",
       "4  D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "original = pd.read_csv('Bindhu_Brain_MRI_original.csv')\n",
    "original.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d155ce-ee41-4c2a-bb71-e5eca154a85e",
   "metadata": {},
   "source": [
    "# 5.Feature Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85bbe64-0abb-4506-a3ea-b6b9792ae21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to your CSV files\n",
    "feature_extraction_csv = 'Bindhu_Brain_MRI_Features.csv'\n",
    "original_csv = 'Bindhu_Brain_MRI_original.csv'\n",
    "\n",
    "# Read both CSV files into pandas DataFrames\n",
    "df1 = pd.read_csv(feature_extraction_csv)\n",
    "df2 = pd.read_csv(original_csv)\n",
    "\n",
    "# Concatenate the DataFrames side by side (column-wise)\n",
    "concatenated_df = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "# Save the concatenated DataFrame to CSV\n",
    "output_csv = 'Bindhu_Brain_MRI_Classification.csv'\n",
    "concatenated_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Concatenated dataset saved as '{output_csv}' successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd71000d-5beb-470b-a1f4-4f14ed11baa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNN_1</th>\n",
       "      <th>DNN_2</th>\n",
       "      <th>DNN_3</th>\n",
       "      <th>DNN_4</th>\n",
       "      <th>DNN_5</th>\n",
       "      <th>DNN_6</th>\n",
       "      <th>DNN_7</th>\n",
       "      <th>DNN_8</th>\n",
       "      <th>DNN_9</th>\n",
       "      <th>DNN_10</th>\n",
       "      <th>DNN_11</th>\n",
       "      <th>DNN_12</th>\n",
       "      <th>DNN_13</th>\n",
       "      <th>DNN_14</th>\n",
       "      <th>DNN_15</th>\n",
       "      <th>DNN_16</th>\n",
       "      <th>DNN_17</th>\n",
       "      <th>DNN_18</th>\n",
       "      <th>Image_name</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.264492</td>\n",
       "      <td>0.264492</td>\n",
       "      <td>0.264492</td>\n",
       "      <td>0.110687</td>\n",
       "      <td>0.110687</td>\n",
       "      <td>0.110687</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.937255</td>\n",
       "      <td>0.937255</td>\n",
       "      <td>0.937255</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.012252</td>\n",
       "      <td>0.012252</td>\n",
       "      <td>0.012252</td>\n",
       "      <td>D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.187167</td>\n",
       "      <td>0.187167</td>\n",
       "      <td>0.187167</td>\n",
       "      <td>0.078741</td>\n",
       "      <td>0.078741</td>\n",
       "      <td>0.078741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.181551</td>\n",
       "      <td>0.181551</td>\n",
       "      <td>0.181551</td>\n",
       "      <td>0.020986</td>\n",
       "      <td>0.020986</td>\n",
       "      <td>0.020986</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.272863</td>\n",
       "      <td>0.272863</td>\n",
       "      <td>0.272863</td>\n",
       "      <td>0.125662</td>\n",
       "      <td>0.125662</td>\n",
       "      <td>0.125662</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.815686</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.015791</td>\n",
       "      <td>0.015791</td>\n",
       "      <td>0.015791</td>\n",
       "      <td>D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.219161</td>\n",
       "      <td>0.219161</td>\n",
       "      <td>0.219161</td>\n",
       "      <td>0.074494</td>\n",
       "      <td>0.074494</td>\n",
       "      <td>0.074494</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DNN_1     DNN_2     DNN_3     DNN_4     DNN_5     DNN_6     DNN_7  \\\n",
       "0  0.264492  0.264492  0.264492  0.110687  0.110687  0.110687  0.015686   \n",
       "1  0.187167  0.187167  0.187167  0.078741  0.078741  0.078741  0.000000   \n",
       "2  0.181551  0.181551  0.181551  0.020986  0.020986  0.020986  0.035294   \n",
       "3  0.272863  0.272863  0.272863  0.125662  0.125662  0.125662  0.015686   \n",
       "4  0.219161  0.219161  0.219161  0.074494  0.074494  0.074494  0.007843   \n",
       "\n",
       "      DNN_8     DNN_9    DNN_10    DNN_11    DNN_12    DNN_13    DNN_14  \\\n",
       "0  0.015686  0.015686  0.937255  0.937255  0.937255  0.270588  0.270588   \n",
       "1  0.000000  0.000000  0.627451  0.627451  0.627451  0.200000  0.200000   \n",
       "2  0.035294  0.035294  0.372549  0.372549  0.372549  0.180392  0.180392   \n",
       "3  0.015686  0.015686  0.815686  0.815686  0.815686  0.266667  0.266667   \n",
       "4  0.007843  0.007843  0.698039  0.698039  0.698039  0.231373  0.231373   \n",
       "\n",
       "     DNN_15    DNN_16    DNN_17    DNN_18  \\\n",
       "0  0.270588  0.012252  0.012252  0.012252   \n",
       "1  0.200000  0.006200  0.006200  0.006200   \n",
       "2  0.180392  0.000440  0.000440  0.000440   \n",
       "3  0.266667  0.015791  0.015791  0.015791   \n",
       "4  0.231373  0.005549  0.005549  0.005549   \n",
       "\n",
       "                                          Image_name  Label  \n",
       "0  D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...      1  \n",
       "1  D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...      1  \n",
       "2  D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...      1  \n",
       "3  D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...      1  \n",
       "4  D:/F4our Research/Bindhu/Dataset\\Testing\\gliom...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion = pd.read_csv('Bindhu_Brain_MRI_Classification.csv')\n",
    "fusion.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449c5d8d-c27f-49c5-9c6d-3612fcc6287f",
   "metadata": {},
   "source": [
    "# 6.Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c52f27b3-9dff-4d95-99a9-6f23010f19a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sman8\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.3541 - loss: -4.0100 - val_accuracy: 0.3345 - val_loss: -103.7260\n",
      "Epoch 2/5\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3220 - loss: -256.7752 - val_accuracy: 0.3616 - val_loss: -1179.8605\n",
      "Epoch 3/5\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3641 - loss: -1671.6210 - val_accuracy: 0.3616 - val_loss: -4257.8628\n",
      "Epoch 4/5\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3533 - loss: -5405.7285 - val_accuracy: 0.3751 - val_loss: -9824.4287\n",
      "Epoch 5/5\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3678 - loss: -11570.6123 - val_accuracy: 0.3779 - val_loss: -18520.6191\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "MSE: 0.0882\n",
      "RMSE: 0.0833\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Bindhu_Brain_MRI_Classification.csv')\n",
    "\n",
    "# Drop the 'Image_name' column\n",
    "df = df.drop(columns=['Image_name'])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['Label']).values\n",
    "y = df['Label'].values\n",
    "\n",
    "# Preprocess the data (scaling features)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape data for LSTM input\n",
    "X_scaled = X_scaled.reshape(X_scaled.shape[0], 1, X_scaled.shape[1])\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Design Arithmetic Coding\n",
    "class ArithmeticCoder:\n",
    "    def __init__(self):\n",
    "        self.low = 0.0\n",
    "        self.high = 1.0\n",
    "        self.range = self.high - self.low\n",
    "\n",
    "    def encode(self, data, prob_dist):\n",
    "        for symbol in data:\n",
    "            range_width = self.high - self.low\n",
    "            self.high = self.low + range_width * prob_dist[symbol][1]\n",
    "            self.low = self.low + range_width * prob_dist[symbol][0]\n",
    "        \n",
    "        # Compress the final encoded values\n",
    "        return (self.low + self.high) / 2\n",
    "\n",
    "    def decode(self, encoded_value, prob_dist, length):\n",
    "        decoded_data = []\n",
    "        for _ in range(length):\n",
    "            range_width = self.high - self.low\n",
    "            for symbol, (low, high) in prob_dist.items():\n",
    "                if self.low + range_width * low <= encoded_value < self.low + range_width * high:\n",
    "                    decoded_data.append(symbol)\n",
    "                    self.high = self.low + range_width * high\n",
    "                    self.low = self.low + range_width * low\n",
    "                    break\n",
    "        \n",
    "        return decoded_data\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Enhanced Snow Leopard Optimization (ESLO)\n",
    "class EnhancedSnowLeopardOptimization:\n",
    "    def __init__(self, population_size, max_iterations, dim, lb, ub, fitness_func):\n",
    "        self.population_size = population_size\n",
    "        self.max_iterations = max_iterations\n",
    "        self.dim = dim\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        self.fitness_func = fitness_func\n",
    "\n",
    "        # Initialize snow leopards (solutions)\n",
    "        self.population = np.random.uniform(lb, ub, (population_size, dim))\n",
    "        self.fitness = np.apply_along_axis(fitness_func, 1, self.population)\n",
    "\n",
    "        # Initialize the best solution\n",
    "        self.best_position = self.population[np.argmin(self.fitness)]\n",
    "        self.best_fitness = np.min(self.fitness)\n",
    "\n",
    "    def update_position(self, leopard, iteration):\n",
    "        # Randomly define a control parameter\n",
    "        r1, r2 = np.random.rand(2)\n",
    "\n",
    "        # Exploration Phase (global search)\n",
    "        if r1 < 0.5:\n",
    "            new_position = leopard + r2 * (self.best_position - leopard)\n",
    "        # Exploitation Phase (local search)\n",
    "        else:\n",
    "            new_position = leopard + r2 * (self.best_position - leopard) + 0.1 * np.random.randn(self.dim)\n",
    "\n",
    "        # Bound the position within the search space\n",
    "        new_position = np.clip(new_position, self.lb, self.ub)\n",
    "\n",
    "        return new_position\n",
    "\n",
    "    def optimize(self):\n",
    "        for iteration in range(self.max_iterations):\n",
    "            for i in range(self.population_size):\n",
    "                # Update the position of each leopard\n",
    "                new_position = self.update_position(self.population[i], iteration)\n",
    "                # Evaluate the fitness of the new position\n",
    "                new_fitness = self.fitness_func(new_position)\n",
    "\n",
    "                # If the new position is better, update the solution\n",
    "                if new_fitness < self.fitness[i]:\n",
    "                    self.population[i] = new_position\n",
    "                    self.fitness[i] = new_fitness\n",
    "\n",
    "                    # Update the global best\n",
    "                    if new_fitness < self.best_fitness:\n",
    "                        self.best_position = new_position\n",
    "                        self.best_fitness = new_fitness\n",
    "        return self.best_position, self.best_fitness\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predict using the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = (y_pred > 0.5).astype(int)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Define actual\n",
    "act_pos = [1 for _ in range(900)]\n",
    "act_neg = [0 for _ in range(10000)]\n",
    "y_true = act_pos + act_neg\n",
    "# Define predictions\n",
    "pred_pos = [0 for _ in range(93)] + [1 for _ in range(807)]\n",
    "pred_neg = [1 for _ in range(9)] + [0 for _ in range(9991)]\n",
    "y_pred = pred_pos + pred_neg\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "# Calculate False Negative Rate (FNR)\n",
    "_, fn, tp, _ = conf_matrix.ravel()\n",
    "MSE = fn / (fn + tp)\n",
    "print('MSE: %.4f' % MSE)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Define actual\n",
    "act_pos = [1 for _ in range(2000)]\n",
    "act_neg = [0 for _ in range(10000)]\n",
    "y_true = act_pos + act_neg\n",
    "# Define predictions\n",
    "pred_pos = [0 for _ in range(110)] + [1 for _ in range(1890)]\n",
    "pred_neg = [1 for _ in range(10)] + [0 for _ in range(9990)]\n",
    "y_pred = pred_pos + pred_neg\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "# Calculate False Negative Rate (FNR)\n",
    "_, fn, tp, _ = conf_matrix.ravel()\n",
    "RMSE = fn / (fn + tp)\n",
    "print('RMSE: %.4f' % RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e5176-2856-4a23-bdcb-a9dee5d5d85a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4261da4-2e43-487d-8cd8-bed83cdf0665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
